{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/kaggle_toxicity/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= df[\"comment_text\"]\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "l=set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\" \".join(map(lambda x: x.lower(),filter(lambda x: x not in l,list(a))))).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(i', 1426),\n",
       " ('type', 1421),\n",
       " ('google', 1420),\n",
       " ('terms', 1417),\n",
       " ('recently', 1415),\n",
       " ('removed.', 1414),\n",
       " ('/', 1411),\n",
       " ('indicate', 1411),\n",
       " ('avoid', 1411),\n",
       " ('attacks', 1407),\n",
       " ('proper', 1407),\n",
       " ('too.', 1406),\n",
       " ('4', 1402),\n",
       " ('god', 1397),\n",
       " ('case,', 1397),\n",
       " ('cited', 1384),\n",
       " ('side', 1383),\n",
       " ('dispute', 1382),\n",
       " ('allowed', 1380),\n",
       " ('city', 1379),\n",
       " ('it?', 1376),\n",
       " ('(the', 1375),\n",
       " ('faith', 1375),\n",
       " ('well.', 1368),\n",
       " ('is.', 1366),\n",
       " ('country', 1361),\n",
       " ('cite', 1360),\n",
       " ('all.', 1356),\n",
       " ('attempt', 1354),\n",
       " ('guys', 1351),\n",
       " ('obvious', 1350),\n",
       " ('longer', 1346),\n",
       " ('short', 1345),\n",
       " ('ban', 1345),\n",
       " ('accept', 1344),\n",
       " ('test', 1341),\n",
       " (\"shouldn't\", 1338),\n",
       " ('2004', 1336),\n",
       " ('deleted.', 1329),\n",
       " ('party', 1328),\n",
       " ('pig', 1325),\n",
       " ('itself', 1325),\n",
       " ('tildes', 1324),\n",
       " ('them,', 1322),\n",
       " ('problems', 1318),\n",
       " ('large', 1318),\n",
       " ('points', 1316),\n",
       " ('definition', 1312),\n",
       " ('human', 1312),\n",
       " ('explanation', 1311),\n",
       " ('username', 1311),\n",
       " ('2006', 1311),\n",
       " ('goes', 1310),\n",
       " ('knowledge', 1307),\n",
       " ('explaining', 1305),\n",
       " ('wp', 1303),\n",
       " (\"they're\", 1303),\n",
       " ('file', 1303),\n",
       " ('banned', 1298),\n",
       " ('game', 1298),\n",
       " ('multiple', 1298),\n",
       " ('living', 1297),\n",
       " ('assume', 1297),\n",
       " ('you?', 1296),\n",
       " (\"what's\", 1296),\n",
       " ('calling', 1295),\n",
       " ('simple', 1294),\n",
       " (\"you'll\", 1291),\n",
       " ('result', 1288),\n",
       " ('refer', 1287),\n",
       " ('example,', 1286),\n",
       " ('5', 1280),\n",
       " ('information.', 1280),\n",
       " ('separate', 1276),\n",
       " ('administrator', 1276),\n",
       " ('one.', 1275),\n",
       " ('\"\\ni', 1274),\n",
       " ('lack', 1272),\n",
       " ('usually', 1269),\n",
       " ('historical', 1265),\n",
       " ('copy', 1258),\n",
       " ('upon', 1258),\n",
       " ('accepted', 1257),\n",
       " ('reasons', 1254),\n",
       " ('all,', 1252),\n",
       " ('\\n\\nif', 1244),\n",
       " ('system', 1244),\n",
       " ('hey', 1242),\n",
       " ('july', 1236),\n",
       " ('entry', 1235),\n",
       " ('date', 1232),\n",
       " ('supposed', 1232),\n",
       " ('books', 1230),\n",
       " ('deal', 1228),\n",
       " ('john', 1227),\n",
       " ('rest', 1226),\n",
       " ('gets', 1221),\n",
       " ('music', 1221),\n",
       " ('conflict', 1221),\n",
       " ('rule', 1220),\n",
       " ('family', 1220),\n",
       " ('couple', 1220),\n",
       " ('contribs)', 1218),\n",
       " ('heard', 1218),\n",
       " ('tagged', 1217),\n",
       " ('source.', 1214),\n",
       " ('respect', 1212),\n",
       " ('valid', 1210),\n",
       " ('asking', 1210),\n",
       " ('disagree', 1210),\n",
       " ('law', 1210),\n",
       " ('(see', 1209),\n",
       " ('act', 1209),\n",
       " ('prove', 1208),\n",
       " ('tags', 1208),\n",
       " ('black', 1206),\n",
       " ('fix', 1205),\n",
       " ('members', 1204),\n",
       " ('huge', 1204),\n",
       " ('white', 1204),\n",
       " ('sex', 1203),\n",
       " ('interesting', 1203),\n",
       " ('\"\\n\\ni', 1198),\n",
       " ('up.', 1198),\n",
       " ('\\n\\nthis', 1196),\n",
       " ('among', 1194),\n",
       " ('university', 1193),\n",
       " ('content,', 1191),\n",
       " ('edits,', 1190),\n",
       " ('fact,', 1189),\n",
       " ('existing', 1189),\n",
       " ('im', 1188),\n",
       " ('produce', 1187),\n",
       " ('german', 1186),\n",
       " (\"let's\", 1184),\n",
       " ('play', 1183),\n",
       " ('thus', 1182),\n",
       " ('pillars', 1179),\n",
       " ('blocking', 1173),\n",
       " ('\\n\\nhi', 1172),\n",
       " ('sandbox', 1171),\n",
       " ('date.', 1171),\n",
       " ('internet', 1170),\n",
       " ('views', 1169),\n",
       " ('help,', 1167),\n",
       " ('jews', 1167),\n",
       " ('sucks', 1166),\n",
       " ('legal', 1164),\n",
       " ('doubt', 1162),\n",
       " ('described', 1161),\n",
       " ('there,', 1156),\n",
       " ('future', 1156),\n",
       " ('2007', 1155),\n",
       " ('status', 1153),\n",
       " ('august', 1152),\n",
       " ('changing', 1152),\n",
       " ('2008', 1152),\n",
       " ('not,', 1151),\n",
       " ('reply', 1151),\n",
       " ('cause', 1151),\n",
       " ('style', 1150),\n",
       " ('film', 1150),\n",
       " ('yourself,', 1149),\n",
       " ('complete', 1146),\n",
       " ('fish', 1145),\n",
       " ('citation', 1143),\n",
       " ('process', 1142),\n",
       " ('sources,', 1141),\n",
       " ('unblock', 1140),\n",
       " ('gave', 1139),\n",
       " ('attention', 1135),\n",
       " ('serious', 1134),\n",
       " ('early', 1133),\n",
       " ('statements', 1132),\n",
       " ('meant', 1130),\n",
       " ('shall', 1127),\n",
       " ('video', 1126),\n",
       " ('(as', 1126),\n",
       " ('indeed', 1126),\n",
       " ('needed', 1126),\n",
       " ('author', 1124),\n",
       " ('email', 1123),\n",
       " ('meaning', 1122),\n",
       " ('people,', 1119),\n",
       " ('primary', 1118),\n",
       " ('edits.', 1117),\n",
       " ('third', 1116),\n",
       " ('truth', 1113),\n",
       " ('available', 1111),\n",
       " ('south', 1111),\n",
       " ('allow', 1111),\n",
       " ('ones', 1109),\n",
       " ('bring', 1108),\n",
       " ('week', 1107),\n",
       " ('uses', 1106),\n",
       " ('giving', 1104),\n",
       " ('takes', 1103),\n",
       " ('merely', 1098),\n",
       " ('close', 1097),\n",
       " ('march', 1097),\n",
       " ('themselves', 1097),\n",
       " ('stay', 1093),\n",
       " ('actions', 1093),\n",
       " ('outside', 1089),\n",
       " ('directly', 1089),\n",
       " ('position', 1088),\n",
       " ('out.', 1086),\n",
       " ('addition', 1084),\n",
       " ('soon', 1084),\n",
       " ('run', 1084),\n",
       " ('hours', 1084),\n",
       " ('towards', 1083),\n",
       " ('speak', 1081),\n",
       " ('story', 1081),\n",
       " ('modern', 1080),\n",
       " ('putting', 1079),\n",
       " ('decided', 1078),\n",
       " ('standard', 1077),\n",
       " ('totally', 1076),\n",
       " ('contest', 1074),\n",
       " ('particularly', 1070),\n",
       " ('happened', 1069),\n",
       " ('coming', 1068),\n",
       " ('kill', 1066),\n",
       " ('\\n\\nplease', 1063),\n",
       " ('category', 1063),\n",
       " ('know,', 1062),\n",
       " ('military', 1062),\n",
       " ('section.', 1061),\n",
       " ('10', 1061),\n",
       " ('contribute', 1058),\n",
       " ('greek', 1057),\n",
       " ('no,', 1055),\n",
       " ('information,', 1055),\n",
       " ('criticism', 1053),\n",
       " ('sourced', 1050),\n",
       " ('except', 1049),\n",
       " ('de', 1049),\n",
       " ('sections', 1048),\n",
       " ('rights', 1047),\n",
       " ('june', 1044),\n",
       " ('absolutely', 1043),\n",
       " ('none', 1041),\n",
       " ('so.', 1041),\n",
       " ('himself', 1041),\n",
       " ('wikiproject', 1040),\n",
       " ('looked', 1039),\n",
       " ('biased', 1038),\n",
       " ('unsigned', 1036),\n",
       " ('wants', 1036),\n",
       " ('violation', 1036),\n",
       " ('january', 1035),\n",
       " ('job', 1035),\n",
       " ('theory', 1034),\n",
       " ('requesting', 1034),\n",
       " ('scientific', 1031),\n",
       " ('otherwise', 1025),\n",
       " ('linked', 1024),\n",
       " (\"you'd\", 1022),\n",
       " ('said,', 1022),\n",
       " ('way.', 1021),\n",
       " ('level', 1020),\n",
       " ('proof', 1017),\n",
       " ('apparently', 1016),\n",
       " ('significant', 1016),\n",
       " ('anonymous', 1015),\n",
       " ('worth', 1015),\n",
       " ('reported', 1013),\n",
       " ('bark', 1013),\n",
       " ('opinions', 1012),\n",
       " ('together', 1010),\n",
       " (\"we're\", 1009),\n",
       " ('area', 1009),\n",
       " ('gives', 1009),\n",
       " ('dick', 1004),\n",
       " ('source,', 1004),\n",
       " ('anyway,', 1003),\n",
       " ('majority', 1002),\n",
       " ('thinking', 1002),\n",
       " ('works', 1001),\n",
       " ('alone', 1000),\n",
       " ('citations', 1000),\n",
       " ('neither', 1000),\n",
       " ('death', 998),\n",
       " ('24', 996),\n",
       " ('meet', 994),\n",
       " ('posting', 994),\n",
       " ('international', 992),\n",
       " ('sometimes', 992),\n",
       " ('highly', 992),\n",
       " ('him.', 992),\n",
       " ('and,', 991),\n",
       " ('named', 990),\n",
       " ('wrong.', 990),\n",
       " ('data', 989),\n",
       " ('balls', 989),\n",
       " ('rationale', 989),\n",
       " ('quality', 988),\n",
       " ('wanker', 988),\n",
       " ('possibly', 986)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(p).most_common(1000)[-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError as error:\n",
    "    print(\"Import error: %s\" % (error))\n",
    "\n",
    "from aif360.algorithms import Transformer\n",
    "\n",
    "\n",
    "class AdversarialDebiasing(Transformer):\n",
    "    \"\"\"Adversarial debiasing is an in-processing technique that learns a\n",
    "    classifier to maximize prediction accuracy and simultaneously reduce an\n",
    "    adversary's ability to determine the protected attribute from the\n",
    "    predictions [5]_. This approach leads to a fair classifier as the\n",
    "    predictions cannot carry any group discrimination information that the\n",
    "    adversary can exploit.\n",
    "\n",
    "    References:\n",
    "        .. [5] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating Unwanted\n",
    "           Biases with Adversarial Learning,\" AAAI/ACM Conference on Artificial\n",
    "           Intelligence, Ethics, and Society, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 unprivileged_groups,\n",
    "                 privileged_groups,\n",
    "                 scope_name,\n",
    "                 sess,\n",
    "                 seed=None,\n",
    "                 adversary_loss_weight=0.1,\n",
    "                 num_epochs=50,\n",
    "                 batch_size=128,\n",
    "                 classifier_num_hidden_units=200,\n",
    "                 debias=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            unprivileged_groups (tuple): Representation for unprivileged groups\n",
    "            privileged_groups (tuple): Representation for privileged groups\n",
    "            scope_name (str): scope name for the tenforflow variables\n",
    "            sess (tf.Session): tensorflow session\n",
    "            seed (int, optional): Seed to make `predict` repeatable.\n",
    "            adversary_loss_weight (float, optional): Hyperparameter that chooses\n",
    "                the strength of the adversarial loss.\n",
    "            num_epochs (int, optional): Number of training epochs.\n",
    "            batch_size (int, optional): Batch size.\n",
    "            classifier_num_hidden_units (int, optional): Number of hidden units\n",
    "                in the classifier model.\n",
    "            debias (bool, optional): Learn a classifier with or without\n",
    "                debiasing.\n",
    "        \"\"\"\n",
    "        super(AdversarialDebiasing, self).__init__(\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            privileged_groups=privileged_groups)\n",
    "\n",
    "        self.scope_name = scope_name\n",
    "        self.seed = seed\n",
    "\n",
    "        self.unprivileged_groups = unprivileged_groups\n",
    "        self.privileged_groups = privileged_groups\n",
    "        if len(self.unprivileged_groups) > 1 or len(self.privileged_groups) > 1:\n",
    "            raise ValueError(\"Only one unprivileged_group or privileged_group supported.\")\n",
    "        self.protected_attribute_name = list(self.unprivileged_groups[0].keys())[0]\n",
    "\n",
    "        self.sess = sess\n",
    "        self.adversary_loss_weight = adversary_loss_weight\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.classifier_num_hidden_units = classifier_num_hidden_units\n",
    "        self.debias = debias\n",
    "\n",
    "        self.features_dim = None\n",
    "        self.features_ph = None\n",
    "        self.protected_attributes_ph = None\n",
    "        self.true_labels_ph = None\n",
    "        self.pred_labels = None\n",
    "\n",
    "    def _classifier_model(self, features, features_dim, keep_prob):\n",
    "        \"\"\"Compute the classifier predictions for the outcome variable.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"classifier_model\"):\n",
    "            W1 = tf.get_variable('W1', [features_dim, self.classifier_num_hidden_units],\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b1 = tf.Variable(tf.zeros(shape=[self.classifier_num_hidden_units]), name='b1')\n",
    "\n",
    "            h1 = tf.nn.relu(tf.matmul(features, W1) + b1)\n",
    "            h1 = tf.nn.dropout(h1, keep_prob=keep_prob)\n",
    "\n",
    "            W2 = tf.get_variable('W2', [self.classifier_num_hidden_units, 1],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b2 = tf.Variable(tf.zeros(shape=[1]), name='b2')\n",
    "\n",
    "            pred_logit = tf.matmul(h1, W2) + b2\n",
    "            pred_label = tf.sigmoid(pred_logit)\n",
    "\n",
    "        return pred_label, pred_logit\n",
    "\n",
    "    def _adversary_model(self, pred_logits, true_labels):\n",
    "        \"\"\"Compute the adversary predictions for the protected attribute.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"adversary_model\"):\n",
    "            c = tf.get_variable('c', initializer=tf.constant(1.0))\n",
    "            s = tf.sigmoid((1 + tf.abs(c)) * pred_logits)\n",
    "\n",
    "            W2 = tf.get_variable('W2', [3, 1],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b2 = tf.Variable(tf.zeros(shape=[1]), name='b2')\n",
    "\n",
    "            pred_protected_attribute_logit = tf.matmul(tf.concat([s, s * true_labels, s * (1.0 - true_labels)], axis=1), W2) + b2\n",
    "            pred_protected_attribute_label = tf.sigmoid(pred_protected_attribute_logit)\n",
    "\n",
    "        return pred_protected_attribute_label, pred_protected_attribute_logit\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        \"\"\"Compute the model parameters of the fair classifier using gradient\n",
    "        descent.\n",
    "\n",
    "        Args:\n",
    "            dataset (BinaryLabelDataset): Dataset containing true labels.\n",
    "\n",
    "        Returns:\n",
    "            AdversarialDebiasing: Returns self.\n",
    "        \"\"\"\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        # Map the dataset labels to 0 and 1.\n",
    "        temp_labels = dataset.labels.copy()\n",
    "\n",
    "        temp_labels[(dataset.labels == dataset.favorable_label).ravel(),0] = 1.0\n",
    "        temp_labels[(dataset.labels == dataset.unfavorable_label).ravel(),0] = 0.0\n",
    "\n",
    "        with tf.variable_scope(self.scope_name):\n",
    "            num_train_samples, self.features_dim = np.shape(dataset.features)\n",
    "\n",
    "            # Setup placeholders\n",
    "            self.features_ph = tf.placeholder(tf.float32, shape=[None, self.features_dim])\n",
    "            self.protected_attributes_ph = tf.placeholder(tf.float32, shape=[None,1])\n",
    "            self.true_labels_ph = tf.placeholder(tf.float32, shape=[None,1])\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # Obtain classifier predictions and classifier loss\n",
    "            self.pred_labels, pred_logits = self._classifier_model(self.features_ph, self.features_dim, self.keep_prob)\n",
    "            pred_labels_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=self.true_labels_ph, logits=pred_logits))\n",
    "\n",
    "            if self.debias:\n",
    "                # Obtain adversary predictions and adversary loss\n",
    "                pred_protected_attributes_labels, pred_protected_attributes_logits = self._adversary_model(pred_logits, self.true_labels_ph)\n",
    "                pred_protected_attributes_loss = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(labels=self.protected_attributes_ph, logits=pred_protected_attributes_logits))\n",
    "\n",
    "            # Setup optimizers with learning rates\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            starter_learning_rate = 0.001\n",
    "            learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                       1000, 0.96, staircase=True)\n",
    "            classifier_opt = tf.train.AdamOptimizer(learning_rate)\n",
    "            if self.debias:\n",
    "                adversary_opt = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "            classifier_vars = [var for var in tf.trainable_variables() if 'classifier_model' in var.name]\n",
    "            if self.debias:\n",
    "                adversary_vars = [var for var in tf.trainable_variables() if 'adversary_model' in var.name]\n",
    "                # Update classifier parameters\n",
    "                adversary_grads = {var: grad for (grad, var) in adversary_opt.compute_gradients(pred_protected_attributes_loss,\n",
    "                                                                                      var_list=classifier_vars)}\n",
    "            normalize = lambda x: x / (tf.norm(x) + np.finfo(np.float32).tiny)\n",
    "\n",
    "            classifier_grads = []\n",
    "            for (grad,var) in classifier_opt.compute_gradients(pred_labels_loss, var_list=classifier_vars):\n",
    "                if self.debias:\n",
    "                    unit_adversary_grad = normalize(adversary_grads[var])\n",
    "                    grad -= tf.reduce_sum(grad * unit_adversary_grad) * unit_adversary_grad\n",
    "                    grad -= self.adversary_loss_weight * adversary_grads[var]\n",
    "                classifier_grads.append((grad, var))\n",
    "            classifier_minimizer = classifier_opt.apply_gradients(classifier_grads, global_step=global_step)\n",
    "\n",
    "            if self.debias:\n",
    "                # Update adversary parameters\n",
    "                adversary_minimizer = adversary_opt.minimize(pred_protected_attributes_loss, var_list=adversary_vars, global_step=global_step)\n",
    "\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(tf.local_variables_initializer())\n",
    "\n",
    "            # Begin training\n",
    "            for epoch in range(self.num_epochs):\n",
    "                shuffled_ids = np.random.choice(num_train_samples, num_train_samples)\n",
    "                for i in range(num_train_samples//self.batch_size):\n",
    "                    batch_ids = shuffled_ids[self.batch_size*i: self.batch_size*(i+1)]\n",
    "                    batch_features = dataset.features[batch_ids]\n",
    "                    batch_labels = np.reshape(temp_labels[batch_ids], [-1,1])\n",
    "                    batch_protected_attributes = np.reshape(dataset.protected_attributes[batch_ids][:,\n",
    "                                                 dataset.protected_attribute_names.index(self.protected_attribute_name)], [-1,1])\n",
    "\n",
    "                    batch_feed_dict = {self.features_ph: batch_features,\n",
    "                                       self.true_labels_ph: batch_labels,\n",
    "                                       self.protected_attributes_ph: batch_protected_attributes,\n",
    "                                       self.keep_prob: 0.8}\n",
    "                    if self.debias:\n",
    "                        _, _, pred_labels_loss_value, pred_protected_attributes_loss_vale = self.sess.run([classifier_minimizer,\n",
    "                                       adversary_minimizer,\n",
    "                                       pred_labels_loss,\n",
    "                                       pred_protected_attributes_loss], feed_dict=batch_feed_dict)\n",
    "                        if i % 200 == 0:\n",
    "                            print(\"epoch %d; iter: %d; batch classifier loss: %f; batch adversarial loss: %f\" % (epoch, i, pred_labels_loss_value,\n",
    "                                                                                     pred_protected_attributes_loss_vale))\n",
    "                    else:\n",
    "                        _, pred_labels_loss_value = self.sess.run(\n",
    "                            [classifier_minimizer,\n",
    "                             pred_labels_loss], feed_dict=batch_feed_dict)\n",
    "                        if i % 200 == 0:\n",
    "                            print(\"epoch %d; iter: %d; batch classifier loss: %f\" % (\n",
    "                            epoch, i, pred_labels_loss_value))\n",
    "        return self\n",
    "\n",
    "    def predict(self, dataset):\n",
    "        \"\"\"Obtain the predictions for the provided dataset using the fair\n",
    "        classifier learned.\n",
    "\n",
    "        Args:\n",
    "            dataset (BinaryLabelDataset): Dataset containing labels that needs\n",
    "                to be transformed.\n",
    "        Returns:\n",
    "            dataset (BinaryLabelDataset): Transformed dataset.\n",
    "        \"\"\"\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        num_test_samples, _ = np.shape(dataset.features)\n",
    "\n",
    "        samples_covered = 0\n",
    "        pred_labels = []\n",
    "        while samples_covered < num_test_samples:\n",
    "            start = samples_covered\n",
    "            end = samples_covered + self.batch_size\n",
    "            if end > num_test_samples:\n",
    "                end = num_test_samples\n",
    "            batch_ids = np.arange(start, end)\n",
    "            batch_features = dataset.features[batch_ids]\n",
    "            batch_labels = np.reshape(dataset.labels[batch_ids], [-1,1])\n",
    "            batch_protected_attributes = np.reshape(dataset.protected_attributes[batch_ids][:,\n",
    "                                         dataset.protected_attribute_names.index(self.protected_attribute_name)], [-1,1])\n",
    "\n",
    "            batch_feed_dict = {self.features_ph: batch_features,\n",
    "                               self.true_labels_ph: batch_labels,\n",
    "                               self.protected_attributes_ph: batch_protected_attributes,\n",
    "                               self.keep_prob: 1.0}\n",
    "\n",
    "            pred_labels += self.sess.run(self.pred_labels, feed_dict=batch_feed_dict)[:,0].tolist()\n",
    "            samples_covered += len(batch_features)\n",
    "\n",
    "        # Mutated, fairer dataset with new labels\n",
    "        dataset_new = dataset.copy(deepcopy = True)\n",
    "        dataset_new.labels = (np.array(pred_labels)>0.5).astype(np.float64).reshape(-1,1)\n",
    "\n",
    "        # Map the dataset labels to back to their original values.\n",
    "        temp_labels = dataset_new.labels.copy()\n",
    "\n",
    "        temp_labels[(dataset_new.labels == 1.0).ravel(), 0] = dataset.favorable_label\n",
    "        temp_labels[(dataset_new.labels == 0.0).ravel(), 0] = dataset.unfavorable_label\n",
    "\n",
    "        dataset_new.labels = temp_labels.copy()\n",
    "\n",
    "        return dataset_new\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
